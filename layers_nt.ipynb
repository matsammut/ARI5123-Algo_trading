{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6193a068",
   "metadata": {},
   "source": [
    "In this notebook we have the functions used for the building of the technical and embedding layers respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dffb4d",
   "metadata": {},
   "source": [
    "We made use of the following 7 indicators for the technical layer:\n",
    "1. Stochastic %K\n",
    "2. William’s %R\n",
    "3. Stochastic %D\n",
    "4. A/D Oscillator\n",
    "5. Momentum\n",
    "6. Disparity\n",
    "7. Rate of Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dfbe38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def calculate_technical_indicator(start_date,end_date):\n",
    "    lookback = 3\n",
    "    adjusted_start = (datetime.strptime(start_date, \"%Y-%m-%d\") - timedelta(days=lookback)).strftime(\"%Y-%m-%d\")\n",
    "    technical_layer = yf.download(\"^GSPC\", start=start_date, end=end_date, interval=\"1d\")\n",
    "    technical_layer.reset_index(inplace=True)\n",
    "    technical_layer.dropna(inplace=True)\n",
    "\n",
    "    # 1. Stochastic %K\n",
    "    low_min = technical_layer['Low'].rolling(window=lookback).min()\n",
    "    high_max = technical_layer['High'].rolling(window=lookback).max()\n",
    "    technical_layer['Stochastic_%K'] = 100 * ((technical_layer['Close'] - low_min) / (high_max - low_min))\n",
    "\n",
    "    # 2. Williams %R\n",
    "    technical_layer[\"Williams_%R\"] = -100 * ((high_max - technical_layer['Close']) / (high_max - low_min))\n",
    "\n",
    "    # 3. Stochastic %D (3-period SMA of %K)\n",
    "    technical_layer['Stochastic_%D'] = technical_layer['Stochastic_%K'].rolling(window=3).mean()\n",
    "\n",
    "    # 4. A/D Oscillator (Accumulation/Distribution Line)\n",
    "    ad = ((technical_layer['Close'] - technical_layer['Low']) - (technical_layer['High'] - technical_layer['Close'])) / (technical_layer['High'] - technical_layer['Low']) * technical_layer['Volume']\n",
    "    technical_layer['AD_Line'] = ad.cumsum()\n",
    "    technical_layer['AD_Oscillator'] = technical_layer['AD_Line'] - technical_layer['AD_Line'].shift(lookback)\n",
    "\n",
    "    # 5. Momentum (Close - Close n periods ago)\n",
    "    technical_layer['Momentum'] = technical_layer['Close'] - technical_layer['Close'].shift(lookback)\n",
    "\n",
    "    # 6. Disparity (Close / Moving Average * 100)\n",
    "    technical_layer['Disparity'] = (technical_layer['Close'] / technical_layer['Close'].rolling(window=lookback).mean()) * 100\n",
    "\n",
    "    # 7. Rate of Change (ROC)\n",
    "    technical_layer['ROC'] = ((technical_layer['Close'] - technical_layer['Close'].shift(lookback)) / technical_layer['Close'].shift(lookback)) * 100\n",
    "    return technical_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb700ee0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fe39085",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "\n",
    "def preprocess_title(title):\n",
    "    title = str(title).lower()\n",
    "    title = title.replace(\"’\", \"'\").replace(\"‘\", \"'\").replace(\"“\", '\"').replace(\"”\", '\"')\n",
    "    tokens = re.findall(r\"\\b[a-zA-Z']+\\b\", title)\n",
    "    return tokens\n",
    "\n",
    "def get_sentence_vector(tokens,model):\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "def calculate_embedding_layer(filename,trading_days):\n",
    "    embedding_layer = pd.read_csv(filename)  \n",
    "    embedding_layer = embedding_layer.sort_values('Date').reset_index(drop=True)  \n",
    "    embedding_layer['Date'] = pd.to_datetime(embedding_layer['Date']).dt.tz_localize(None).dt.date\n",
    "\n",
    "    token_list = embedding_layer['Article_title'].apply(preprocess_title) \n",
    "    model = Word2Vec(sentences=token_list, vector_size=100, window=5, min_count=1, workers=4)\n",
    "    embedding_layer['sentence_vector'] = token_list.apply(lambda tokens: get_sentence_vector(tokens, model))\n",
    "\n",
    "    daily_news = embedding_layer.groupby('Date')['sentence_vector'].apply(lambda vecs: np.mean(list(vecs), axis=0)).reset_index()\n",
    "    daily_news_trading_days = daily_news[daily_news['Date'].isin(trading_days)].reset_index(drop=True)   \n",
    "    return daily_news_trading_days"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
