{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3ae4e62",
   "metadata": {},
   "source": [
    "The goal of this code is the building of an SI-RCNN model to forcast intraday directional movements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe87951a",
   "metadata": {},
   "source": [
    "The first step is the loading of seven technical indicators from our stock of choice. For the remit of this assignment we used the S&P 500.\n",
    "\n",
    "We made use of the following 7 indicators:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bc86e1",
   "metadata": {},
   "source": [
    "1. Stochastic %K\n",
    "2. William’s %R\n",
    "3. Stochastic %D\n",
    "4. A/D Oscillator\n",
    "5. Momentum\n",
    "6. Disparity\n",
    "7. Rate of Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1dfe32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yfinance as yf\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import ta\n",
    "\n",
    "# data = yf.download(\"^GSPC\", start=\"2023-01-01\", end=\"2025-01-01\", interval=\"1d\")\n",
    "# data.dropna(inplace=True)\n",
    "\n",
    "# # 1. SMA (Simple Moving Average - 20 days)\n",
    "# data['SMA_20'] = data['Close'].rolling(window=20).mean()\n",
    "\n",
    "# # 2. EMA (Exponential Moving Average - 20 days)\n",
    "# data['EMA_20'] = data['Close'].ewm(span=20, adjust=False).mean()\n",
    "\n",
    "# # 3. RSI (Relative Strength Index - 14 days)\n",
    "# delta = data['Close'].diff()\n",
    "# gain = np.where(delta > 0, delta, 0)\n",
    "# loss = np.where(delta < 0, -delta, 0)\n",
    "# avg_gain = pd.Series(gain.reshape(-1)).rolling(window=14).mean()\n",
    "# avg_loss = pd.Series(loss.reshape(-1)).rolling(window=14).mean()\n",
    "# rs = avg_gain / avg_loss\n",
    "# data['RSI_14'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "# # 4. MACD (Moving Average Convergence Divergence)\n",
    "# ema_12 = data['Close'].ewm(span=12, adjust=False).mean()\n",
    "# ema_26 = data['Close'].ewm(span=26, adjust=False).mean()\n",
    "# data['MACD'] = ema_12 - ema_26\n",
    "\n",
    "# # 5. Stochastic Oscillator %K (14-day)\n",
    "# low_14 = data['Low'].rolling(window=14).min()\n",
    "# high_14 = data['High'].rolling(window=14).max()\n",
    "# data['Stochastic_K'] = 100 * ((data['Close'] - low_14) / (high_14 - low_14))\n",
    "\n",
    "# # 6. ATR (Average True Range - 14 days)\n",
    "# high_low = data['High'] - data['Low']\n",
    "# high_close = np.abs(data['High'] - data['Close'].shift())\n",
    "# low_close = np.abs(data['Low'] - data['Close'].shift())\n",
    "# true_range = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
    "# data['ATR'] = true_range.rolling(window=14).mean()\n",
    "\n",
    "# # 7. OBV (On-Balance Volume)\n",
    "# obv = (np.sign(data['Close'].diff()) * data['Volume']).fillna(0).cumsum()\n",
    "# data['OBV'] = obv\n",
    "\n",
    "# # Keep only indicator columns\n",
    "# indicators = data[['SMA_20', 'EMA_20', 'RSI_14', 'MACD', 'Stochastic_K', 'ATR', 'OBV']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "686f9a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price        Date Stochastic_%K Williams_%R Stochastic_%D AD_Oscillator  \\\n",
      "Ticker                                                                    \n",
      "15     2023-01-25     90.252829   -9.747171     90.951325  1.302313e+10   \n",
      "16     2023-01-26     99.547583   -0.452417     93.453797  1.936106e+10   \n",
      "17     2023-01-27     89.097404  -10.902596     92.965938  1.618603e+10   \n",
      "18     2023-01-30     64.761217  -35.238783     84.468735  1.680585e+10   \n",
      "19     2023-01-31     91.560900   -8.439100     81.806507  1.764679e+10   \n",
      "\n",
      "Price     Momentum   Disparity       ROC  \n",
      "Ticker                                    \n",
      "15      163.250000  101.656858  4.236991  \n",
      "16      252.329834  102.309142  6.626134  \n",
      "17      175.479980  102.241487  4.505170  \n",
      "18      125.679932  100.688509  3.229112  \n",
      "19      157.350098  101.875888  4.014801  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\gianm\\AppData\\Local\\Temp\\ipykernel_63248\\2257969786.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  technical_indicators.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "\n",
    "# Ensure the data is sorted by date\n",
    "technical_layer = yf.download(\"^GSPC\", start=\"2023-01-01\", end=\"2025-01-01\", interval=\"1d\")\n",
    "technical_layer.reset_index(inplace=True)\n",
    "technical_layer.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# Parameters\n",
    "lookback = 14  # typical lookback for most of these indicators\n",
    "\n",
    "# 1. Stochastic %K\n",
    "low_min = technical_layer['Low'].rolling(window=lookback).min()\n",
    "high_max = technical_layer['High'].rolling(window=lookback).max()\n",
    "technical_layer['Stochastic_%K'] = 100 * ((technical_layer['Close'] - low_min) / (high_max - low_min))\n",
    "\n",
    "# 2. Williams %R\n",
    "technical_layer[\"Williams_%R\"] = -100 * ((high_max - technical_layer['Close']) / (high_max - low_min))\n",
    "\n",
    "# 3. Stochastic %D (3-period SMA of %K)\n",
    "technical_layer['Stochastic_%D'] = technical_layer['Stochastic_%K'].rolling(window=3).mean()\n",
    "\n",
    "# 4. A/D Oscillator (Accumulation/Distribution Line)\n",
    "ad = ((technical_layer['Close'] - technical_layer['Low']) - (technical_layer['High'] - technical_layer['Close'])) / (technical_layer['High'] - technical_layer['Low']) * technical_layer['Volume']\n",
    "technical_layer['AD_Line'] = ad.cumsum()\n",
    "technical_layer['AD_Oscillator'] = technical_layer['AD_Line'] - technical_layer['AD_Line'].shift(lookback)\n",
    "\n",
    "# 5. Momentum (Close - Close n periods ago)\n",
    "technical_layer['Momentum'] = technical_layer['Close'] - technical_layer['Close'].shift(lookback)\n",
    "\n",
    "# 6. Disparity (Close / Moving Average * 100)\n",
    "technical_layer['Disparity'] = (technical_layer['Close'] / technical_layer['Close'].rolling(window=lookback).mean()) * 100\n",
    "\n",
    "# 7. Rate of Change (ROC)\n",
    "technical_layer['ROC'] = ((technical_layer['Close'] - technical_layer['Close'].shift(lookback)) / technical_layer['Close'].shift(lookback)) * 100\n",
    "\n",
    "# Display relevant columns\n",
    "technical_indicators = technical_layer[['Date', 'Stochastic_%K', 'Williams_%R', 'Stochastic_%D','AD_Oscillator', 'Momentum', 'Disparity', 'ROC']]\n",
    "technical_indicators.dropna(inplace=True)\n",
    "print(technical_indicators.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add7467f",
   "metadata": {},
   "source": [
    "The next step was to create another input of financial news sentence embeddings, for this we used the FNSPID dataset which hold millions of financial news records covering S&P 500 companies.\n",
    "\n",
    "https://github.com/Zdong104/FNSPID_Financial_News_Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd364db",
   "metadata": {},
   "source": [
    "First we tokenize the titles, we handled quotations as this caused some parsing issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cad0751f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                        Date  \\\n",
      "0   2020-06-05 06:30:54 UTC   \n",
      "1   2020-06-03 06:45:20 UTC   \n",
      "2   2020-05-26 00:30:07 UTC   \n",
      "3   2020-05-22 08:45:06 UTC   \n",
      "4   2020-05-22 07:38:59 UTC   \n",
      "5   2020-05-22 07:23:25 UTC   \n",
      "6   2020-05-22 05:36:20 UTC   \n",
      "7   2020-05-22 05:07:04 UTC   \n",
      "8   2020-05-22 04:37:59 UTC   \n",
      "9   2020-05-22 04:06:17 UTC   \n",
      "10  2020-05-22 00:00:00 UTC   \n",
      "11  2020-05-22 00:00:00 UTC   \n",
      "12  2020-05-21 00:00:00 UTC   \n",
      "13  2020-05-21 00:00:00 UTC   \n",
      "14  2020-05-21 00:00:00 UTC   \n",
      "15  2020-05-21 00:00:00 UTC   \n",
      "16  2020-05-18 00:00:00 UTC   \n",
      "17  2020-05-16 00:00:00 UTC   \n",
      "18  2020-05-15 00:00:00 UTC   \n",
      "19  2020-05-08 00:00:00 UTC   \n",
      "20  2020-05-05 00:00:00 UTC   \n",
      "21  2020-05-01 00:00:00 UTC   \n",
      "22  2020-04-28 00:00:00 UTC   \n",
      "23  2020-04-23 00:00:00 UTC   \n",
      "24  2020-04-22 00:00:00 UTC   \n",
      "25  2020-04-14 00:00:00 UTC   \n",
      "26  2020-04-08 00:00:00 UTC   \n",
      "27  2020-04-06 00:00:00 UTC   \n",
      "28  2020-04-02 00:00:00 UTC   \n",
      "29  2020-04-01 00:00:00 UTC   \n",
      "30  2020-03-31 00:00:00 UTC   \n",
      "\n",
      "                                        Article_title Stock_symbol  \\\n",
      "0             Stocks That Hit 52-Week Highs On Friday            A   \n",
      "1          Stocks That Hit 52-Week Highs On Wednesday            A   \n",
      "2                       71 Biggest Movers From Friday            A   \n",
      "3        46 Stocks Moving In Friday's Mid-Day Session            A   \n",
      "4   B of A Securities Maintains Neutral on Agilent...            A   \n",
      "5   CFRA Maintains Hold on Agilent Technologies, L...            A   \n",
      "6   UBS Maintains Neutral on Agilent Technologies,...            A   \n",
      "7   Agilent Technologies shares are trading higher...            A   \n",
      "8   Wells Fargo Maintains Overweight on Agilent Te...            A   \n",
      "9          10 Biggest Price Target Changes For Friday            A   \n",
      "10    30 Stocks Moving in Friday's Pre-Market Session            A   \n",
      "11  SVB Leerink Maintains Outperform on Agilent Te...            A   \n",
      "12  8 Stocks Moving In Thursday's After-Hours Session            A   \n",
      "13  Agilent Technologies shares are trading higher...            A   \n",
      "14  Agilent Technologies Q2 Adj. EPS $0.71 Beats $...            A   \n",
      "15                Earnings Scheduled For May 21, 2020            A   \n",
      "16  Agilent Technologies Receives FDA Approval for...            A   \n",
      "17  Q1 13F Roundup: How Buffett, Einhorn, Ackman A...            A   \n",
      "18  Pershing Square 13F Shows Fund Raises Stake In...            A   \n",
      "19  How Bill Ackman Successfully Navigated Coronav...            A   \n",
      "20  Shares of several healthcare companies are tra...            A   \n",
      "21  Shares of several healthcare companies are tra...            A   \n",
      "22  UBS Maintains Neutral on Agilent Technologies,...            A   \n",
      "23  Agilent Reports FDA Approval For PD-L1 Compani...            A   \n",
      "24  Agilent Reports Has Become Top-Level Sponsor O...            A   \n",
      "25             Agilent Withdraws Q2 And FY20 Guidance            A   \n",
      "26  Shares of several companies in the auto dealer...            A   \n",
      "27  Shares of several healthcare companies are tra...            A   \n",
      "28  Stifel Maintains Hold on Agilent Technologies,...            A   \n",
      "29  Shares of several healthcare companies are tra...            A   \n",
      "30  Int'l. Air Transport Authority Chief Economist...            A   \n",
      "\n",
      "                                                  Url  \\\n",
      "0   https://www.benzinga.com/news/20/06/16190091/s...   \n",
      "1   https://www.benzinga.com/news/20/06/16170189/s...   \n",
      "2   https://www.benzinga.com/news/20/05/16103463/7...   \n",
      "3   https://www.benzinga.com/news/20/05/16095921/4...   \n",
      "4   https://www.benzinga.com/news/20/05/16095304/b...   \n",
      "5   https://www.benzinga.com/news/20/05/16095163/c...   \n",
      "6   https://www.benzinga.com/news/20/05/16094027/u...   \n",
      "7   https://www.benzinga.com/wiim/20/05/16093805/a...   \n",
      "8   https://www.benzinga.com/news/20/05/16093505/w...   \n",
      "9   https://www.benzinga.com/analyst-ratings/price...   \n",
      "10  https://www.benzinga.com/news/20/05/16092879/3...   \n",
      "11  https://www.benzinga.com/news/20/05/16092270/s...   \n",
      "12  https://www.benzinga.com/news/20/05/16089803/8...   \n",
      "13  https://www.benzinga.com/wiim/20/05/16089218/a...   \n",
      "14  https://www.benzinga.com/news/earnings/20/05/1...   \n",
      "15  https://www.benzinga.com/news/earnings/20/05/1...   \n",
      "16  https://www.benzinga.com/news/20/05/16054223/a...   \n",
      "17  https://www.benzinga.com/news/20/05/16051311/q...   \n",
      "18  https://www.benzinga.com/general/hedge-funds/2...   \n",
      "19  https://www.benzinga.com/general/education/20/...   \n",
      "20  https://www.benzinga.com/wiim/20/05/15957697/s...   \n",
      "21  https://www.benzinga.com/20/05/15935673/shares...   \n",
      "22  https://www.benzinga.com/news/20/04/15897306/u...   \n",
      "23  https://www.benzinga.com/news/20/04/15864339/a...   \n",
      "24  https://www.benzinga.com/news/20/04/15855436/a...   \n",
      "25  https://www.benzinga.com/news/20/04/15796369/a...   \n",
      "26  https://www.benzinga.com/wiim/20/04/15769071/s...   \n",
      "27  https://www.benzinga.com/wiim/20/04/15748126/s...   \n",
      "28  https://www.benzinga.com/news/20/04/15728603/s...   \n",
      "29  https://www.benzinga.com/wiim/20/04/15717065/s...   \n",
      "30  https://www.benzinga.com/news/20/03/15705690/i...   \n",
      "\n",
      "                  Publisher  Author  Article  Lsa_summary  Luhn_summary  \\\n",
      "0         Benzinga Insights     NaN      NaN          NaN           NaN   \n",
      "1         Benzinga Insights     NaN      NaN          NaN           NaN   \n",
      "2                Lisa Levin     NaN      NaN          NaN           NaN   \n",
      "3                Lisa Levin     NaN      NaN          NaN           NaN   \n",
      "4                Vick Meyer     NaN      NaN          NaN           NaN   \n",
      "5   vishwanath@benzinga.com     NaN      NaN          NaN           NaN   \n",
      "6   vishwanath@benzinga.com     NaN      NaN          NaN           NaN   \n",
      "7         Benzinga Newsdesk     NaN      NaN          NaN           NaN   \n",
      "8   vishwanath@benzinga.com     NaN      NaN          NaN           NaN   \n",
      "9                Lisa Levin     NaN      NaN          NaN           NaN   \n",
      "10               Lisa Levin     NaN      NaN          NaN           NaN   \n",
      "11  vishwanath@benzinga.com     NaN      NaN          NaN           NaN   \n",
      "12             Tyree Gorges     NaN      NaN          NaN           NaN   \n",
      "13        Benzinga Newsdesk     NaN      NaN          NaN           NaN   \n",
      "14        Benzinga Newsdesk     NaN      NaN          NaN           NaN   \n",
      "15               Lisa Levin     NaN      NaN          NaN           NaN   \n",
      "16            Luke J Jacobi     NaN      NaN          NaN           NaN   \n",
      "17             Wayne Duggan     NaN      NaN          NaN           NaN   \n",
      "18        Benzinga Newsdesk     NaN      NaN          NaN           NaN   \n",
      "19             Wayne Duggan     NaN      NaN          NaN           NaN   \n",
      "20        Benzinga Newsdesk     NaN      NaN          NaN           NaN   \n",
      "21        Benzinga Newsdesk     NaN      NaN          NaN           NaN   \n",
      "22  vishwanath@benzinga.com     NaN      NaN          NaN           NaN   \n",
      "23        Benzinga Newsdesk     NaN      NaN          NaN           NaN   \n",
      "24        Benzinga Newsdesk     NaN      NaN          NaN           NaN   \n",
      "25        Benzinga Newsdesk     NaN      NaN          NaN           NaN   \n",
      "26        Benzinga Newsdesk     NaN      NaN          NaN           NaN   \n",
      "27        Benzinga Newsdesk     NaN      NaN          NaN           NaN   \n",
      "28               Vick Meyer     NaN      NaN          NaN           NaN   \n",
      "29        Benzinga Newsdesk     NaN      NaN          NaN           NaN   \n",
      "30        Benzinga Newsdesk     NaN      NaN          NaN           NaN   \n",
      "\n",
      "    Textrank_summary  Lexrank_summary  \n",
      "0                NaN              NaN  \n",
      "1                NaN              NaN  \n",
      "2                NaN              NaN  \n",
      "3                NaN              NaN  \n",
      "4                NaN              NaN  \n",
      "5                NaN              NaN  \n",
      "6                NaN              NaN  \n",
      "7                NaN              NaN  \n",
      "8                NaN              NaN  \n",
      "9                NaN              NaN  \n",
      "10               NaN              NaN  \n",
      "11               NaN              NaN  \n",
      "12               NaN              NaN  \n",
      "13               NaN              NaN  \n",
      "14               NaN              NaN  \n",
      "15               NaN              NaN  \n",
      "16               NaN              NaN  \n",
      "17               NaN              NaN  \n",
      "18               NaN              NaN  \n",
      "19               NaN              NaN  \n",
      "20               NaN              NaN  \n",
      "21               NaN              NaN  \n",
      "22               NaN              NaN  \n",
      "23               NaN              NaN  \n",
      "24               NaN              NaN  \n",
      "25               NaN              NaN  \n",
      "26               NaN              NaN  \n",
      "27               NaN              NaN  \n",
      "28               NaN              NaN  \n",
      "29               NaN              NaN  \n",
      "30               NaN              NaN  >\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "\n",
    "embedding_layer = pd.read_csv('All_external_subset.csv')  \n",
    "print(embedding_layer.head)\n",
    "embedding_layer = embedding_layer.sort_values('Date').reset_index(drop=True)  \n",
    "\n",
    "def preprocess_title(title):\n",
    "    title = title.lower()\n",
    "    title = title.replace(\"’\", \"'\").replace(\"‘\", \"'\").replace(\"“\", '\"').replace(\"”\", '\"')\n",
    "    tokens = re.findall(r\"\\b[a-zA-Z']+\\b\", title)\n",
    "    return tokens\n",
    "\n",
    "token_list = embedding_layer['Article_title'].apply(preprocess_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bff039",
   "metadata": {},
   "source": [
    "Next we create a sentence embeddings by averaging the word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7059066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=token_list, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "def get_sentence_vector(tokens):\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "embedding_layer['sentence_vector'] = token_list.apply(get_sentence_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c3432a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of 0     [0.00038041366, 0.00038732446, 0.00061241444, ...\n",
      "1     [-0.0010377998, 0.00042375515, -0.0011617246, ...\n",
      "2     [-0.0023824708, -0.0012906671, 0.0009930803, 0...\n",
      "3     [-0.0007787028, 0.0014723241, -0.0006502996, -...\n",
      "4     [-0.0023002836, 0.001976771, -0.00018580035, -...\n",
      "5     [-0.0010352622, -0.0015254191, -0.002226289, -...\n",
      "6     [-0.00014356375, -0.00014395872, -0.0015540291...\n",
      "7     [0.0007607373, 0.0022731104, -0.0003411403, 0....\n",
      "8     [-0.0008626608, -0.0023146372, 0.002436483, 0....\n",
      "9     [-0.0008346233, 0.0016315253, 0.0006025097, -0...\n",
      "10    [-0.00014000069, 0.002407807, 0.0018011844, -0...\n",
      "11    [-0.0008903536, 0.0041253697, -0.0019558165, 0...\n",
      "12    [-0.00420256, 0.001401495, 0.0012031626, 0.002...\n",
      "13    [0.0015997442, 0.0040907594, 0.0014146743, -0....\n",
      "14    [-0.0014908734, 0.0027777825, 0.001969549, 0.0...\n",
      "15    [0.0014033166, 0.0020460426, -0.0011179068, -9...\n",
      "16    [0.001953044, 0.00066828105, 0.0009675104, 0.0...\n",
      "17    [0.0032971348, -0.0011330238, -0.0027351317, -...\n",
      "18    [-0.00018068735, 0.000385504, -0.00068583805, ...\n",
      "19    [-0.0023984618, 0.00049329695, 0.0017930693, 0...\n",
      "20    [0.001902024, -0.00034319222, -0.0031952264, 0...\n",
      "21    [0.0017553534, 0.0009279386, -0.0027275821, -9...\n",
      "22    [-0.0023270848, -0.0008484444, 0.0018316925, 0...\n",
      "23    [0.001953044, 0.00066828105, 0.0009675104, 0.0...\n",
      "24    [-0.0015265128, -0.0010131574, 0.0028580765, 0...\n",
      "25    [-0.0019872696, -0.0021185125, 0.0005397282, 0...\n",
      "26    [-0.0028656696, 0.00084226695, 0.0011121533, 0...\n",
      "27    [-0.0009733803, -0.0018607078, 0.0005945036, 0...\n",
      "28    [-0.0041690194, 0.004640135, -0.0011659208, -0...\n",
      "29    [0.0019277496, -0.0028309973, -0.0026490756, -...\n",
      "30    [0.0027100462, -0.00020415589, -0.002690406, -...\n",
      "Name: sentence_vector, dtype: object>\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer['sentence_vector'].head)\n",
    "embedding_layer['sentence_vector'].to_csv(\"sentence_vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "188287e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: torch.Size([27, 4, 100])\n",
      "CNN output shape: torch.Size([27, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "day_to_vectors = embedding_layer.groupby('Date')['sentence_vector'].apply(list)\n",
    "day_tensors = []\n",
    "for vectors in day_to_vectors:\n",
    "    tensor = torch.tensor(vectors, dtype=torch.float32)\n",
    "    day_tensors.append(tensor)\n",
    "\n",
    "# # Example: get shape info\n",
    "# for i, tensor in enumerate(day_tensors[:3]):\n",
    "#     print(f\"Day {i+1}: shape {tensor.shape}\")  # (num_titles, 100)\n",
    "\n",
    "# Define CNN model\n",
    "class NewsCNN(nn.Module):\n",
    "    def __init__(self, embedding_dim=100, out_channels=64, kernel_size=3, dropout=0.5):\n",
    "        super(NewsCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=embedding_dim, out_channels=out_channels, kernel_size=kernel_size, padding=1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, embedding_dim) → need (batch_size, embedding_dim, seq_len)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool1d(x, kernel_size=x.size(2))  # Temporal max pooling over sequence\n",
    "        x = x.squeeze(2)  # Remove the pooled dimension\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "# Example: Create model and test on a batch of days\n",
    "model = NewsCNN()\n",
    "\n",
    "# Create batch: pad sequences to max length (optional, if using batch training)\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "batch = pad_sequence(day_tensors, batch_first=True)  # Shape: (batch_size, max_seq_len, 100)\n",
    "print(\"Batch shape:\", batch.shape)\n",
    "\n",
    "# Forward pass\n",
    "output = model(batch)\n",
    "print(\"CNN output shape:\", output.shape)  # (batch_size, out_channels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
