{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3ae4e62",
   "metadata": {},
   "source": [
    "The goal of this code is the building of an SI-RCNN model to forcast intraday directional movements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe87951a",
   "metadata": {},
   "source": [
    "The first step is the loading of seven technical indicators from our stock of choice. For the remit of this assignment we used the S&P 500.\n",
    "\n",
    "We made use of the following 7 indicators:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bc86e1",
   "metadata": {},
   "source": [
    "1. Stochastic %K\n",
    "2. William’s %R\n",
    "3. Stochastic %D\n",
    "4. A/D Oscillator\n",
    "5. Momentum\n",
    "6. Disparity\n",
    "7. Rate of Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1dfe32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ta\n",
    "\n",
    "data = yf.download(\"^GSPC\", start=\"2023-01-01\", end=\"2025-01-01\", interval=\"1d\")\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# 1. SMA (Simple Moving Average - 20 days)\n",
    "data['SMA_20'] = data['Close'].rolling(window=20).mean()\n",
    "\n",
    "# 2. EMA (Exponential Moving Average - 20 days)\n",
    "data['EMA_20'] = data['Close'].ewm(span=20, adjust=False).mean()\n",
    "\n",
    "# 3. RSI (Relative Strength Index - 14 days)\n",
    "delta = data['Close'].diff()\n",
    "gain = np.where(delta > 0, delta, 0)\n",
    "loss = np.where(delta < 0, -delta, 0)\n",
    "avg_gain = pd.Series(gain.reshape(-1)).rolling(window=14).mean()\n",
    "avg_loss = pd.Series(loss.reshape(-1)).rolling(window=14).mean()\n",
    "rs = avg_gain / avg_loss\n",
    "data['RSI_14'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "# 4. MACD (Moving Average Convergence Divergence)\n",
    "ema_12 = data['Close'].ewm(span=12, adjust=False).mean()\n",
    "ema_26 = data['Close'].ewm(span=26, adjust=False).mean()\n",
    "data['MACD'] = ema_12 - ema_26\n",
    "\n",
    "# 5. Stochastic Oscillator %K (14-day)\n",
    "low_14 = data['Low'].rolling(window=14).min()\n",
    "high_14 = data['High'].rolling(window=14).max()\n",
    "data['Stochastic_K'] = 100 * ((data['Close'] - low_14) / (high_14 - low_14))\n",
    "\n",
    "# 6. ATR (Average True Range - 14 days)\n",
    "high_low = data['High'] - data['Low']\n",
    "high_close = np.abs(data['High'] - data['Close'].shift())\n",
    "low_close = np.abs(data['Low'] - data['Close'].shift())\n",
    "true_range = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
    "data['ATR'] = true_range.rolling(window=14).mean()\n",
    "\n",
    "# 7. OBV (On-Balance Volume)\n",
    "obv = (np.sign(data['Close'].diff()) * data['Volume']).fillna(0).cumsum()\n",
    "data['OBV'] = obv\n",
    "\n",
    "# Keep only indicator columns\n",
    "indicators = data[['SMA_20', 'EMA_20', 'RSI_14', 'MACD', 'Stochastic_K', 'ATR', 'OBV']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "686f9a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price        Date Stochastic_%K Williams_%R Stochastic_%D AD_Oscillator  \\\n",
      "Ticker                                                                    \n",
      "15     2023-01-25     90.252829   -9.747171     90.951325  1.302313e+10   \n",
      "16     2023-01-26     99.547583   -0.452417     93.453797  1.936106e+10   \n",
      "17     2023-01-27     89.097404  -10.902596     92.965938  1.618603e+10   \n",
      "18     2023-01-30     64.761217  -35.238783     84.468735  1.680585e+10   \n",
      "19     2023-01-31     91.560900   -8.439100     81.806507  1.764679e+10   \n",
      "\n",
      "Price     Momentum   Disparity       ROC  \n",
      "Ticker                                    \n",
      "15      163.250000  101.656858  4.236991  \n",
      "16      252.329834  102.309142  6.626134  \n",
      "17      175.479980  102.241487  4.505170  \n",
      "18      125.679932  100.688509  3.229112  \n",
      "19      157.350098  101.875888  4.014801  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\gianm\\AppData\\Local\\Temp\\ipykernel_195676\\925566104.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  technical_indicators.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "\n",
    "# Ensure the data is sorted by date\n",
    "df = yf.download(\"^GSPC\", start=\"2023-01-01\", end=\"2025-01-01\", interval=\"1d\")\n",
    "df.reset_index(inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# Parameters\n",
    "lookback = 14  # typical lookback for most of these indicators\n",
    "\n",
    "# 1. Stochastic %K\n",
    "low_min = df['Low'].rolling(window=lookback).min()\n",
    "high_max = df['High'].rolling(window=lookback).max()\n",
    "df['Stochastic_%K'] = 100 * ((df['Close'] - low_min) / (high_max - low_min))\n",
    "\n",
    "# 2. Williams %R\n",
    "df[\"Williams_%R\"] = -100 * ((high_max - df['Close']) / (high_max - low_min))\n",
    "\n",
    "# 3. Stochastic %D (3-period SMA of %K)\n",
    "df['Stochastic_%D'] = df['Stochastic_%K'].rolling(window=3).mean()\n",
    "\n",
    "# 4. A/D Oscillator (Accumulation/Distribution Line)\n",
    "ad = ((df['Close'] - df['Low']) - (df['High'] - df['Close'])) / (df['High'] - df['Low']) * df['Volume']\n",
    "df['AD_Line'] = ad.cumsum()\n",
    "df['AD_Oscillator'] = df['AD_Line'] - df['AD_Line'].shift(lookback)\n",
    "\n",
    "# 5. Momentum (Close - Close n periods ago)\n",
    "df['Momentum'] = df['Close'] - df['Close'].shift(lookback)\n",
    "\n",
    "# 6. Disparity (Close / Moving Average * 100)\n",
    "df['Disparity'] = (df['Close'] / df['Close'].rolling(window=lookback).mean()) * 100\n",
    "\n",
    "# 7. Rate of Change (ROC)\n",
    "df['ROC'] = ((df['Close'] - df['Close'].shift(lookback)) / df['Close'].shift(lookback)) * 100\n",
    "\n",
    "# Display relevant columns\n",
    "technical_indicators = df[['Date', 'Stochastic_%K', 'Williams_%R', 'Stochastic_%D','AD_Oscillator', 'Momentum', 'Disparity', 'ROC']]\n",
    "technical_indicators.dropna(inplace=True)\n",
    "print(technical_indicators.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add7467f",
   "metadata": {},
   "source": [
    "The next step was to create another input of financial news sentence embeddings, for this we used the FNSPID dataset which hold millions of financial news records covering S&P 500 companies.\n",
    "\n",
    "https://github.com/Zdong104/FNSPID_Financial_News_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7059066b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of 0     [int'l, air, transport, authority, chief, econ...\n",
      "1     [shares, of, several, healthcare, companies, a...\n",
      "2     [stifel, maintains, hold, on, agilent, technol...\n",
      "3     [shares, of, several, healthcare, companies, a...\n",
      "4     [shares, of, several, companies, in, the, auto...\n",
      "5                   [agilent, withdraws, and, guidance]\n",
      "6     [agilent, reports, has, become, top, level, sp...\n",
      "7     [agilent, reports, fda, approval, for, pd, com...\n",
      "8     [ubs, maintains, neutral, on, agilent, technol...\n",
      "9     [shares, of, several, healthcare, companies, a...\n",
      "10    [shares, of, several, healthcare, companies, a...\n",
      "11    [how, bill, ackman, successfully, navigated, c...\n",
      "12    [pershing, square, shows, fund, raises, stake,...\n",
      "13    [roundup, how, buffett, einhorn, ackman, and, ...\n",
      "14    [agilent, technologies, receives, fda, approva...\n",
      "15                      [earnings, scheduled, for, may]\n",
      "16    [agilent, technologies, shares, are, trading, ...\n",
      "17    [stocks, moving, in, thursday's, after, hours,...\n",
      "18    [agilent, technologies, adj, eps, beats, estim...\n",
      "19    [svb, leerink, maintains, outperform, on, agil...\n",
      "20    [stocks, moving, in, friday's, pre, market, se...\n",
      "21       [biggest, price, target, changes, for, friday]\n",
      "22    [wells, fargo, maintains, overweight, on, agil...\n",
      "23    [agilent, technologies, shares, are, trading, ...\n",
      "24    [ubs, maintains, neutral, on, agilent, technol...\n",
      "25    [cfra, maintains, hold, on, agilent, technolog...\n",
      "26    [b, of, a, securities, maintains, neutral, on,...\n",
      "27    [stocks, moving, in, friday's, mid, day, session]\n",
      "28                      [biggest, movers, from, friday]\n",
      "29      [stocks, that, hit, week, highs, on, wednesday]\n",
      "30         [stocks, that, hit, week, highs, on, friday]\n",
      "Name: tokens, dtype: object>\n",
      "<bound method NDFrame.head of 0     [0.00038041366, 0.00038732446, 0.00061241444, ...\n",
      "1     [-0.0010377998, 0.00042375515, -0.0011617246, ...\n",
      "2     [-0.0023824708, -0.0012906671, 0.0009930803, 0...\n",
      "3     [-0.0007787028, 0.0014723241, -0.0006502996, -...\n",
      "4     [-0.0023002836, 0.001976771, -0.00018580035, -...\n",
      "5     [-0.0010352622, -0.0015254191, -0.002226289, -...\n",
      "6     [-0.00014356375, -0.00014395872, -0.0015540291...\n",
      "7     [0.0007607373, 0.0022731104, -0.0003411403, 0....\n",
      "8     [-0.0008626608, -0.0023146372, 0.002436483, 0....\n",
      "9     [-0.0008346233, 0.0016315253, 0.0006025097, -0...\n",
      "10    [-0.00014000069, 0.002407807, 0.0018011844, -0...\n",
      "11    [-0.0008903536, 0.0041253697, -0.0019558165, 0...\n",
      "12    [-0.00420256, 0.001401495, 0.0012031626, 0.002...\n",
      "13    [0.0015997442, 0.0040907594, 0.0014146743, -0....\n",
      "14    [-0.0014908734, 0.0027777825, 0.001969549, 0.0...\n",
      "15    [0.0014033166, 0.0020460426, -0.0011179068, -9...\n",
      "16    [0.001953044, 0.00066828105, 0.0009675104, 0.0...\n",
      "17    [0.0032971348, -0.0011330238, -0.0027351317, -...\n",
      "18    [-0.00018068735, 0.000385504, -0.00068583805, ...\n",
      "19    [-0.0023984618, 0.00049329695, 0.0017930693, 0...\n",
      "20    [0.001902024, -0.00034319222, -0.0031952264, 0...\n",
      "21    [0.0017553534, 0.0009279386, -0.0027275821, -9...\n",
      "22    [-0.0023270848, -0.0008484444, 0.0018316925, 0...\n",
      "23    [0.001953044, 0.00066828105, 0.0009675104, 0.0...\n",
      "24    [-0.0015265128, -0.0010131574, 0.0028580765, 0...\n",
      "25    [-0.0019872696, -0.0021185125, 0.0005397282, 0...\n",
      "26    [-0.0028656696, 0.00084226695, 0.0011121533, 0...\n",
      "27    [-0.0009733803, -0.0018607078, 0.0005945036, 0...\n",
      "28    [-0.0041690194, 0.004640135, -0.0011659208, -0...\n",
      "29    [0.0019277496, -0.0028309973, -0.0026490756, -...\n",
      "30    [0.0027100462, -0.00020415589, -0.002690406, -...\n",
      "Name: sentence_vector, dtype: object>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gianm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "# Ensure NLTK resources are available\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('All_external_subset.csv')  \n",
    "#print(df['Article_title'].head())\n",
    "df = df.sort_values('Date').reset_index(drop=True)  \n",
    "\n",
    "def preprocess_title(title):\n",
    "    title = title.lower()\n",
    "    title = title.replace(\"’\", \"'\").replace(\"‘\", \"'\").replace(\"“\", '\"').replace(\"”\", '\"')\n",
    "    tokens = re.findall(r\"\\b[a-zA-Z']+\\b\", title)\n",
    "    return tokens\n",
    "\n",
    "df['tokens'] = df['Article_title'].apply(preprocess_title)\n",
    "print(df['tokens'].head)\n",
    "\n",
    "# Build vocabulary\n",
    "all_tokens = [token for tokens in df['tokens'] for token in tokens]\n",
    "vocab = sorted(set(all_tokens))\n",
    "word_to_index = {word: idx for idx, word in enumerate(vocab)}\n",
    "\n",
    "# One-hot encode titles\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "encoder.fit(np.array(vocab).reshape(-1, 1))\n",
    "\n",
    "def one_hot_encode(tokens):\n",
    "    indices = [word_to_index[word] for word in tokens if word in word_to_index]\n",
    "    one_hot = np.zeros(len(vocab))\n",
    "    one_hot[indices] = 1\n",
    "    return one_hot\n",
    "\n",
    "df['one_hot'] = df['tokens'].apply(one_hot_encode)\n",
    "\n",
    "# Train Word2Vec model\n",
    "model = Word2Vec(sentences=df['tokens'], vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Generate sentence embeddings by averaging word vectors\n",
    "def get_sentence_vector(tokens):\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "df['sentence_vector'] = df['tokens'].apply(get_sentence_vector)\n",
    "print(df['sentence_vector'].head)\n",
    "\n",
    "# Now, df['sentence_vector'] contains the embedding for each title"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
